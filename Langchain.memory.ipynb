{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9f99f94-160d-48d6-8fa1-748038f009fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b72411f-8ef7-4451-aa90-d19af1a5a623",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86f49324-4288-4a84-aa3f-e1d5b679f1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dda9f732-b207-4491-9391-a9e5ae0bfd5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': ''}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory = ConversationBufferMemory()\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2b623ee-7d26-4c5d-8ce4-c8830ae75a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.chat_memory.add_user_message('Hi! My name is Harsha.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08c67a12-355f-4e7f-9f8e-8a2cbf788e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Hi! My name is Harsha.'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8840ec8f-c496-4db9-9890-0dddc844d150",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(api_key = api_key, model ='gpt-3.5-turbo', temperature = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23e4f7f6-0d48-44d9-b6cf-a64cc1f4c007",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=llm, verbose=True, memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6fd0a1c0-6305-4145-9546-34c798db2ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi! My name is Harsha.\n",
      "Human: What is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello Harsha! Your name is Harsha.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input = 'What is my name?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ae85521-71ee-48ff-8cd1-f7594aacb3ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Hi! My name is Harsha.\\nHuman: What is my name?\\nAI: Hello Harsha! Your name is Harsha.'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e99fc2ca-2ad0-422e-b04e-def6b22558cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: Hi! My name is Harsha.\\nHuman: What is my name?\\nAI: Hello Harsha! Your name is Harsha.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d40c9e3-f47e-4a06-9c60-65e0a88de5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83400393-57b7-498c-8c81-5ec7db745d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_memory = ConversationBufferWindowMemory(k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c80075bb-fa7a-4511-8497-462bfab79441",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_memory.chat_memory.add_user_message('Hi! My name is Harsha.')\n",
    "window_memory.chat_memory.add_ai_message('Hi Harsha. My name is Siri!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce4e68bf-f125-4efc-ace8-5d4dc95f7caa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Hi! My name is Harsha.\\nAI: Hi Harsha. My name is Siri!'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cb16c6c1-21f8-4062-b5ba-e12b21becd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_window_memory = ConversationChain(llm = llm, memory = window_memory, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "38f5cd43-eef9-447e-bf95-ff79c454380a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi! My name is Harsha.\n",
      "AI: Hi Harsha. My name is Siri!\n",
      "Human: What is your name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'My name is Siri.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_window_memory.predict(input = 'What is your name?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4fa06081-b319-4e3e-9ef0-e856cea4c190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: What is your name?\\nAI: My name is Siri.'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7c8f69a1-76e6-4708-86d2-74ce8963563b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: What is your name?\n",
      "AI: My name is Siri.\n",
      "Human: How are you doing?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm doing well, thank you for asking! I've been busy processing information and learning new things. How about you?\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_window_memory.predict(input = 'How are you doing?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7782a3f6-1293-497e-ae52-84c734036ea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: How are you doing?\\nAI: I'm doing well, thank you for asking! I've been busy processing information and learning new things. How about you?\"}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7ae74327-08fc-4eb1-b04e-b5bfeb594bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: How are you doing?\n",
      "AI: I'm doing well, thank you for asking! I've been busy processing information and learning new things. How about you?\n",
      "Human: What is your name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I don't have a specific name, but you can call me AI or any other nickname you'd like. I'm here to help with any questions you have.\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_window_memory.predict(input = 'What is your name?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "afea832b-c821-4f11-a527-7c7e673e1efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dabef679-aecf-4307-b70f-cc977387bdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_window_memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=30)\n",
    "token_window_memory.chat_memory.add_user_message('Hi! My name is Harsha.')\n",
    "token_window_memory.chat_memory.add_ai_message('Hi Harsha. My name is Siri!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "58746a2c-df04-49db-a799-5835909cd9d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: Hi! My name is Harsha.\\nAI: Hi Harsha. My name is Siri!'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_window_memory.buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d85ed2b2-61a2-4d9e-92b3-db39d8f78431",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_memory_chain = ConversationChain(llm = llm, memory = token_window_memory, verbose= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b4a1bb64-5c01-486f-87ea-5753fca145d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi! My name is Harsha.\n",
      "AI: Hi Harsha. My name is Siri!\n",
      "Human: What is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your name is Harsha.'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_memory_chain.predict(input = 'What is my name?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0efe71f9-a3ea-4f36-b5da-4ef80a3d91a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: What is my name?\\nAI: Your name is Harsha.'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_window_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "450ef7a0-e2fd-453a-be5a-1f625ba3da65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: What is my name?\n",
      "AI: Your name is Harsha.\n",
      "Human: What is 1+1?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1+1 equals 2.'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_memory_chain.predict(input = 'What is 1+1?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "18672acc-41e2-4b44-b83c-876ba0a2a4d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: What is 1+1?\\nAI: 1+1 equals 2.'}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_window_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e24cae23-d406-45f1-ac38-7ef10dc0f9ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: What is 1+1?\n",
      "AI: 1+1 equals 2.\n",
      "Human: What is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, I do not have access to personal information such as your name.\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_memory_chain.predict(input = 'What is my name?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3e88794e-ee84-4959-8779-ed7ed35ca660",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "# create a long string\n",
    "schedule = \"There is a meeting at 8am with your product team. \\\n",
    "You will need your powerpoint presentation prepared. \\\n",
    "9am-12pm have time to work on your LangChain \\\n",
    "project which will go quickly because Langchain is such a powerful tool. \\\n",
    "At Noon, lunch at the italian resturant with a customer who is driving \\\n",
    "from over an hour away to meet you to understand the latest in AI. \\\n",
    "Be sure to bring your laptop to show the latest LLM demo.\"\n",
    "\n",
    "summary_memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)\n",
    "summary_memory.save_context({\"input\": \"Hello! My name is Harsha\"}, {\"output\": \"What's up\"})\n",
    "summary_memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4ee7c398-8b07-4992-85dc-909780d54a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Hello! My name is Harsha\\nAI: What's up\\nHuman: Not much, just hanging\\nAI: Cool\"}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ca4f4746-3a69-483d-a369-8832b4e4d496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hello! My name is Harsha\n",
      "AI: What's up\n",
      "Human: Not much, just hanging\n",
      "AI: Cool\n",
      "Human: What is my name\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your name is Harsha.'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_memory_chain = ConversationChain(llm = llm, memory = summary_memory, verbose = True)\n",
    "summary_memory_chain.predict(input='What is my name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ddebac96-4040-43c1-8a00-950d83931ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_memory.save_context({\"input\": \"What is on the schedule today?\"}, \n",
    "                    {\"output\": f\"{schedule}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c49e89e0-d9db-414d-963d-dbb359705a07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'System: The human introduces themselves as Harsha to the AI. They discuss the schedule for the day, including a meeting with the product team, work on the LangChain project, and a lunch meeting with a customer interested in AI. The AI provides details about each event and reminds Harsha to bring their laptop for the LLM demo.'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1cc6d3f1-4aea-40e1-be3f-0745d1248296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: The human introduces themselves as Harsha to the AI. They discuss the schedule for the day, including a meeting with the product team, work on the LangChain project, and a lunch meeting with a customer interested in AI. The AI provides details about each event and reminds Harsha to bring their laptop for the LLM demo.\n",
      "Human: What is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your name is Harsha.'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_memory_chain.predict(input= 'What is my name?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6834880f-2725-47f3-bc85-311035ea9d49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'System: The human introduces themselves as Harsha to the AI. They discuss the schedule for the day, including a meeting with the product team, work on the LangChain project, and a lunch meeting with a customer interested in AI. The AI provides details about each event and reminds Harsha to bring their laptop for the LLM demo.\\nHuman: What is my name?\\nAI: Your name is Harsha.'}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb49e0fa-a049-4c7d-940e-9c1f3da91ac3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
